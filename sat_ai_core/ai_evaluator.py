import os
import time
import logging
import hashlib
import sqlite3
from datetime import datetime
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from openai import OpenAI
from rich.console import Console
from rich.markdown import Markdown
from sat_ai_core.api_throttler import ApiThrottler, ThrottlerError

PROMPT_VERSION = "v2"

env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), ".env")
load_dotenv(dotenv_path=env_path)

logging.basicConfig(level=logging.INFO, format="[%(asctime)s] %(levelname)s - %(message)s")

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("âŒ OPENAI_API_KEY chÆ°a Ä‘Æ°á»£c set trong .env!")

MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
client = OpenAI(api_key=api_key)
throttler = ApiThrottler(min_interval=2.0, max_retries=5, max_wait=25.0, per_model=True)

DB_PATH = "ai_cache.db"
os.makedirs(os.path.dirname(DB_PATH) or ".", exist_ok=True)

def _init_db():
    conn = sqlite3.connect(DB_PATH)
    try:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS cache (
                key TEXT PRIMARY KEY,
                model TEXT,
                created_at TEXT,
                tokens INTEGER,
                response TEXT NOT NULL
            );
        """)
    except sqlite3.OperationalError:
        for col, definition in [
            ("model", "TEXT DEFAULT 'unknown'"),
            ("created_at", "TEXT DEFAULT CURRENT_TIMESTAMP"),
            ("tokens", "INTEGER DEFAULT 0"),
        ]:
            try:
                conn.execute(f"ALTER TABLE cache ADD COLUMN {col} {definition};")
            except sqlite3.OperationalError:
                pass
    conn.commit()
    conn.close()

def _get_cache(key: str, model: str) -> Optional[str]:
    conn = sqlite3.connect(DB_PATH)
    row = conn.execute("SELECT response FROM cache WHERE key=? AND model=?", (key, model)).fetchone()
    conn.close()
    return row[0] if row else None

def _set_cache(key: str, model: str, text: str, tokens: int):
    conn = sqlite3.connect(DB_PATH)
    conn.execute(
        "INSERT OR REPLACE INTO cache VALUES (?, ?, ?, ?, ?)",
        (key, model, datetime.now().isoformat(), tokens, text),
    )
    conn.commit()
    conn.close()

_init_db()

def _shorten_text(text: str, max_len: int = 120) -> str:
    if not isinstance(text, str):
        return ""
    t = " ".join(text.split())
    return t if len(t) <= max_len else t[:max_len].rsplit(" ", 1)[0] + "â€¦"

def _history_summary(history: List[Dict[str, Any]]) -> str:
    lines = []
    for h in history:
        res = "âœ… Ä‘Ãºng" if h.get("answered_correctly") else "âŒ sai"
        skill = h.get("skill", "Unknown")
        q = _shorten_text(h.get("question", ""))
        lines.append(f"- [{res}] *{skill}*: {q}")
    return "\n".join(lines)

def evaluate_student_performance(
    history: List[Dict[str, Any]],
    final_theta: float,
    *,
    language: str = "vi",
    temperature: float = 0.5,
    verbose: bool = True,
) -> str:
    if not history:
        return "âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u bÃ i thi Ä‘á»ƒ Ä‘Ã¡nh giÃ¡."
    try:
        theta = round(float(final_theta), 2)
    except Exception:
        return "ğŸš¨ GiÃ¡ trá»‹ Î¸ khÃ´ng há»£p lá»‡!"

    summary = _history_summary(history)

    sys_vi = (
        "Báº¡n lÃ  chuyÃªn gia giÃ¡o dá»¥c SAT. Viáº¿t bÃ¡o cÃ¡o Markdown vá»›i 4 pháº§n:\n"
        "â‘  **Tá»•ng quan nÄƒng lá»±c:** mÃ´ táº£ trÃ¬nh Ä‘á»™ vÃ  Ä‘á»™ á»•n Ä‘á»‹nh dá»±a trÃªn Î¸.\n"
        "â‘¡ **Ká»¹ nÄƒng máº¡nh / yáº¿u:** liá»‡t kÃª cÃ¡c ká»¹ nÄƒng tá»‘t vÃ  yáº¿u.\n"
        "â‘¢ **Gá»£i Ã½ luyá»‡n táº­p:** Ä‘á» xuáº¥t 3â€“5 hÆ°á»›ng cáº£i thiá»‡n cá»¥ thá»ƒ.\n"
        "â‘£ **Dá»± Ä‘oÃ¡n cáº¥p Ä‘á»™ SAT:** Beginner / Intermediate / Advanced.\n"
        "Viáº¿t ngáº¯n gá»n, rÃµ rÃ ng, cÃ³ Ä‘á»‹nh dáº¡ng Markdown."
    )

    sys_en = (
        "You are an SAT education expert. Write a Markdown report with 4 sections:\n"
        "â‘  Overview of ability (based on theta)\n"
        "â‘¡ Strengths & Weaknesses\n"
        "â‘¢ Study Recommendations (3â€“5 concise bullet points)\n"
        "â‘£ Predicted SAT Level (Beginner / Intermediate / Advanced)"
    )

    system_prompt = sys_vi if language == "vi" else sys_en

    prompt = f"""
{system_prompt}

ğŸ“Š **ThÃ´ng tin bÃ i thi**
- NÄƒng lá»±c cuá»‘i (Î¸): {theta}
- Sá»‘ cÃ¢u há»i: {len(history)}

ğŸ“„ **Chi tiáº¿t tá»«ng cÃ¢u:**
{summary}
""".strip()

    key_src = f"{PROMPT_VERSION}::{MODEL}::{prompt}"
    key = hashlib.sha256(key_src.encode()).hexdigest()
    cached = _get_cache(key, MODEL)

    console = Console()
    if cached:
        if verbose:
            console.print("âš¡ [bold yellow]ÄÃ£ cÃ³ cache bÃ¡o cÃ¡o AI![/bold yellow]\n")
            console.print(Markdown(cached))
        return cached

    console.print("\nğŸ¤– [cyan]Äang táº¡o bÃ¡o cÃ¡o nÄƒng lá»±c báº±ng OpenAI...[/cyan]\n")

    try:
        response = throttler.safe_openai_chat(
            client,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt},
            ],
            model=MODEL,
            temperature=temperature,
        )

        report = response.choices[0].message.content.strip()
        token_count = len(report.split())
        _set_cache(key, MODEL, report, token_count)

        console.print("\nâœ… [green]BÃ¡o cÃ¡o hoÃ n táº¥t![/green]")
        logging.info(f"ğŸ“Š Tokens ~ {token_count}\n")
        console.print("\nğŸ“˜ [bold]BÃO CÃO:[/bold]\n")
        console.print(Markdown(report))
        return report

    except ThrottlerError as e:
        logging.error(f"âŒ API tháº¥t báº¡i sau {e.attempts} láº§n retry: {e.last_exception}")
        return f"Lá»—i API: {e}"
    except Exception as e:
        logging.error(f"ğŸš¨ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh khi gá»i OpenAI: {e}")
        return f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}"

if __name__ == "__main__":
    demo_history = [
        {"question": "Náº¿u 3x + 5 = 20, tÃ¬m x?", "skill": "Algebra", "answered_correctly": True},
        {"question": "TÃ­nh diá»‡n tÃ­ch hÃ¬nh trÃ²n bÃ¡n kÃ­nh 4.", "skill": "Geometry", "answered_correctly": False},
        {"question": "Má»™t Ä‘Æ°á»ng tháº³ng cÃ³ há»‡ sá»‘ gÃ³c báº±ng 2, Ä‘i qua (1,3)...", "skill": "Functions", "answered_correctly": True},
    ]
    report = evaluate_student_performance(demo_history, 0.85)
