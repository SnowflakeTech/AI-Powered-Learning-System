import os
import re
import time
import hashlib
import sqlite3
import logging
from datetime import datetime
from typing import Optional
from dotenv import load_dotenv
from openai import OpenAI
from rich.console import Console
from rich.markdown import Markdown
from sat_ai_core.api_throttler import ApiThrottler, ThrottlerError

PROMPT_VERSION = "v4"

env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), ".env")
load_dotenv(dotenv_path=env_path)
logging.basicConfig(level=logging.INFO, format="[%(asctime)s] %(levelname)s - %(message)s")

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("‚ùå OPENAI_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p trong .env!")

MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
client = OpenAI(api_key=api_key)
throttler = ApiThrottler(min_interval=2.0, max_retries=5, max_wait=25.0, per_model=True)
DB_PATH = "ai_cache.db"
os.makedirs(os.path.dirname(DB_PATH) or ".", exist_ok=True)

def _init_db():
    conn = sqlite3.connect(DB_PATH)
    try:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS cache (
                key TEXT PRIMARY KEY,
                model TEXT,
                created_at TEXT,
                tokens INTEGER,
                response TEXT NOT NULL
            );
        """)
    except sqlite3.OperationalError:
        for col, definition in [
            ("model", "TEXT DEFAULT 'unknown'"),
            ("created_at", "TEXT DEFAULT CURRENT_TIMESTAMP"),
            ("tokens", "INTEGER DEFAULT 0"),
        ]:
            try:
                conn.execute(f"ALTER TABLE cache ADD COLUMN {col} {definition};")
            except sqlite3.OperationalError:
                pass
    conn.commit()
    conn.close()

def _get_cache(key: str, model: str) -> Optional[str]:
    conn = sqlite3.connect(DB_PATH)
    row = conn.execute("SELECT response FROM cache WHERE key=? AND model=?", (key, model)).fetchone()
    conn.close()
    return row[0] if row else None

def _set_cache(key: str, model: str, text: str, tokens: int):
    conn = sqlite3.connect(DB_PATH)
    conn.execute(
        "INSERT OR REPLACE INTO cache VALUES (?, ?, ?, ?, ?)",
        (key, model, datetime.now().isoformat(), tokens, text),
    )
    conn.commit()
    conn.close()

_init_db()

def _build_tagged_prompt(question: str, correct_choice: str) -> str:
    return f"""
B·∫°n l√† gia s∆∞ SAT chuy√™n nghi·ªáp. Tr·∫£ l·ªùi CH√çNH X√ÅC theo M·∫™U TH·∫∫ d∆∞·ªõi ƒë√¢y.
<MESSAGE>
<SUMMARY>
- T√≥m t·∫Øt ng·∫Øn g·ªçn ƒë·ªÅ b√†i (1‚Äì3 c√¢u).
</SUMMARY>
<STEPS>
- Li·ªát k√™ c√°c b∆∞·ªõc gi·∫£i ng·∫Øn g·ªçn, m·ªói b∆∞·ªõc 1 g·∫°ch ƒë·∫ßu d√≤ng.
- C√≥ th·ªÉ k√®m c√¥ng th·ª©c ng·∫Øn trong `code` ho·∫∑c $math$.
</STEPS>
<CONCLUSION>
- K·∫øt lu·∫≠n r√µ r√†ng; n√≥i ƒë√°p √°n ƒë√∫ng l√† g√¨ v√† v√¨ sao.
</CONCLUSION>
</MESSAGE>
[C√ÇU H·ªéI]: {question}
[ƒê√ÅP √ÅN ƒê√öNG]: {correct_choice}
"""

def _extract_tag(text: str, tag: str) -> str:
    m = re.search(rf"<{tag}>(.*?)</{tag}>", text, flags=re.DOTALL | re.IGNORECASE)
    return (m.group(1) if m else "").strip()

def _sanitize_lines(s: str) -> str:
    s = re.sub(r"^\s*#{1,6}\s*", "", s, flags=re.MULTILINE)
    s = re.sub(r"[ \t]+", " ", s)
    s = re.sub(r"\s*\n\s*\n\s*\n+", "\n\n", s)
    return s.strip()

def _steps_to_bullets(steps: str) -> str:
    parts = re.split(r"(?:\n|^)\s*[-‚Ä¢*]\s*|(?:\r?\n)+", steps)
    parts = [p.strip(" -‚Ä¢*\t") for p in parts if p and p.strip(" -‚Ä¢*\t")]
    more = []
    for p in parts:
        more.extend(re.split(r"\s*\d+\.\s+", p))
    bullets = [b for b in more if b.strip()]
    return "\n".join(f"- {b.strip()}" for b in bullets) if bullets else "- (Kh√¥ng c√≥ b∆∞·ªõc gi·∫£i r√µ r√†ng)"

def _format_response(raw: str, correct_choice: str) -> str:
    raw = _sanitize_lines(raw)
    summary = _extract_tag(raw, "SUMMARY")
    steps = _extract_tag(raw, "STEPS")
    concl = _extract_tag(raw, "CONCLUSION")
    if not (summary and steps and concl):
        text = _sanitize_lines(raw)
        blocks = re.split(r"(?i)(?:t√≥m t·∫Øt|summary)|(?:b∆∞·ªõc|steps)|(?:k·∫øt lu·∫≠n|conclusion)", text)
        summary = (blocks[1] if len(blocks) > 1 else text).strip()
        steps = (blocks[2] if len(blocks) > 2 else "").strip()
        concl = (blocks[3] if len(blocks) > 3 else "").strip()
    steps_md = _steps_to_bullets(steps)
    state = "‚úÖ ƒê√öNG" if correct_choice and correct_choice in (summary + steps_md + concl) else "üîé Ki·ªÉm tra l·∫°i"
    return f"""
### üßæ 1 T√≥m t·∫Øt ƒë·ªÅ
{summary}

---

### üß† 2 C√°c b∆∞·ªõc gi·∫£i
{steps_md}

---

### üéØ 3 K·∫øt lu·∫≠n ({state})
{concl}
""".strip()

def explain_answer(question: str, correct_choice: str, verbose: bool = True) -> str:
    prompt = _build_tagged_prompt(question, correct_choice)
    key_src = f"{PROMPT_VERSION}::{MODEL}::{prompt}"
    key = hashlib.sha256(key_src.encode()).hexdigest()
    cached = _get_cache(key, MODEL)
    console = Console()
    if cached:
        if verbose:
            console.print("‚ö° [bold yellow]ƒê√£ c√≥ cache, kh√¥ng c·∫ßn g·ªçi API.[/bold yellow]\n")
            console.print(Markdown(cached))
        return cached
    console.print(f"\nüìò [cyan]ƒêang gi·∫£i th√≠ch c√¢u h·ªèi b·∫±ng {MODEL}...[/cyan]\n")
    try:
        response = throttler.safe_openai_chat(
            client,
            messages=[
                {"role": "system", "content": "B·∫°n l√† gia s∆∞ SAT chuy√™n nghi·ªáp, tr·∫£ l·ªùi r√µ r√†ng v√† d·ªÖ hi·ªÉu."},
                {"role": "user", "content": prompt},
            ],
            model=MODEL,
            temperature=0.6,
        )
        full_text = response.choices[0].message.content or ""
        token_count = len(full_text.split())
        formatted = _format_response(full_text, correct_choice)
        _set_cache(key, MODEL, formatted, token_count)
        console.print("\n‚úÖ [green]Ho√†n t·∫•t gi·∫£i th√≠ch![/green]")
        logging.info(f"üìä Tokens ~ {token_count}")
        console.print("\nüéØ [bold]K·∫øt qu·∫£:[/bold]\n")
        console.print(Markdown(formatted))
        return formatted
    except ThrottlerError as e:
        logging.error(f"‚ùå API th·∫•t b·∫°i sau {e.attempts} l·∫ßn retry: {e.last_exception}")
        return f"L·ªói API: {e}"
    except Exception as e:
        logging.error(f"üö® L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")
        return f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

if __name__ == "__main__":
    q = "M·ªôt h√¨nh ch·ªØ nh·∫≠t c√≥ chi·ªÅu d√†i g·∫•p ƒë√¥i chi·ªÅu r·ªông. Chu vi l√† 36 th√¨ di·ªán t√≠ch l√† bao nhi√™u?"
    a = "81"
    explain_answer(q, a, verbose=True)
