import os
import time
import logging
from typing import List, Dict, Any, Optional
from google import genai

# âœ… Logging
logging.basicConfig(level=logging.INFO, format="[%(asctime)s] %(levelname)s - %(message)s")

# âœ… Gemini Client
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("âŒ GOOGLE_API_KEY chÆ°a Ä‘Æ°á»£c set!")
client = genai.Client(api_key=api_key)

MODEL = "gemini-2.5-flash"

# -----------------------
# ğŸ”¹ HÃ m phá»¥ trá»£
# -----------------------
def shorten_text(text: str, max_len: int = 160) -> str:
    if not isinstance(text, str): return ""
    t = " ".join(text.split())
    return t if len(t) <= max_len else t[:max_len].rsplit(" ", 1)[0] + "â€¦"


def history_to_summary(history: List[Dict[str, Any]]) -> str:
    lines = []
    for h in history:
        result = "âœ… Ä‘Ãºng" if h.get("answered_correctly") else "âŒ sai"
        skill = h.get("skill", "Unknown")
        question = shorten_text(h.get("question", ""))
        lines.append(f"- [{result}] *{skill}*: {question}")
    return "\n".join(lines)


# -----------------------
# âœ… Retry cho Gemini
# -----------------------
def call_gemini_with_retry(prompt: str, *, temperature: float, max_tokens: int, retries: int = 3) -> Optional[str]:

    for attempt in range(1, retries + 1):
        try:
            start = time.time()
            resp = client.models.generate_content(
                model=MODEL,
                contents=prompt
            )
            latency = time.time() - start

            text = resp.text.strip()
            token_est = len(text.split())

            logging.info(f"âœ… Gemini success (lat={latency:.2f}s, tokensâ‰ˆ{token_est})")
            return text

        except Exception as e:
            wait = 2 ** attempt
            logging.warning(f"âš ï¸ Retry {attempt}/{retries} after {wait}s: {e}")
            time.sleep(wait)

    logging.error("ğŸš¨ API FAILED")
    return None


# -----------------------
# ğŸ§  Táº¡o bÃ¡o cÃ¡o há»c lá»±c há»c sinh
# -----------------------
def evaluate_student_performance(
    history: List[Dict[str, Any]],
    final_theta: float,
    *,
    language: str = "vi",
    temperature: float = 0.4,
    max_tokens: int = 800,
) -> str:

    if not history:
        return "âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u bÃ i thi."

    try:
        theta = round(float(final_theta), 2)
    except Exception:
        return "ğŸš¨ final_theta khÃ´ng há»£p lá»‡!"

    summary_text = history_to_summary(history)

    system_prompt_vi = (
        "Báº¡n lÃ  chuyÃªn gia giÃ¡o dá»¥c SAT. HÃ£y táº¡o bÃ¡o cÃ¡o báº±ng Markdown rÃµ rÃ ng, gá»“m 4 pháº§n:\n"
        "1ï¸âƒ£ Tá»•ng quan nÄƒng lá»±c\n"
        "2ï¸âƒ£ Ká»¹ nÄƒng máº¡nh/yáº¿u\n"
        "3ï¸âƒ£ Gá»£i Ã½ luyá»‡n táº­p 3â€“5 má»¥c tiÃªu\n"
        "4ï¸âƒ£ Dá»± Ä‘oÃ¡n má»©c SAT tÆ°Æ¡ng á»©ng (Beginner / Intermediate / Advanced)\n\n"
        "Viáº¿t ngáº¯n gá»n, cÃ³ bullet vÃ  tiÃªu Ä‘á» phá»¥."
    )

    system_prompt_en = (
        "You are an SAT education expert. Write a Markdown report with 4 sections:\n"
        "1 Overview\n"
        "2 Strengths & Weaknesses\n"
        "3 Study Suggestions (3â€“5 bullets)\n"
        "4 Predicted SAT Level (B/I/A)\n"
        "Use clear bullets and sub-headings."
    )

    sys = system_prompt_vi if language == "vi" else system_prompt_en

    full_prompt = f"""
{sys}

ğŸ“Š **ThÃ´ng tin bÃ i thi**
- NÄƒng lá»±c cuá»‘i cÃ¹ng (Î¸): {theta}
- Sá»‘ cÃ¢u há»i: {len(history)}
- Chi tiáº¿t tá»«ng cÃ¢u:
{summary_text}
""".strip()

    report = call_gemini_with_retry(
        full_prompt,
        temperature=temperature,
        max_tokens=max_tokens,
    )

    return report or "ğŸš¨ KhÃ´ng thá»ƒ táº¡o bÃ¡o cÃ¡o sau retry. Thá»­ láº¡i sau."
